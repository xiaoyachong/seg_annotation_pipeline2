{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbede706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 image files to process\n",
      "\n",
      "Processing: 20211222_125057_petiole4_00012\n",
      "  Image shape: (2560, 2560), dtype: float32, mode: L\n",
      "  Mask shape: (2560, 2560), unique values: 2085\n",
      "  Created color map for 2084 unique objects\n",
      "  Saved overlay to ./data/overlay/20211222_125057_petiole4_00012_overlay.tif\n",
      "\n",
      "All files processed!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(\"./data/overlay\", exist_ok=True)\n",
    "\n",
    "# Get all .tiff and .tif files from images directory\n",
    "image_files = glob.glob(\"./data/images/*.tiff\") + glob.glob(\"./data/images/*.tif\")\n",
    "\n",
    "print(f\"Found {len(image_files)} image files to process\\n\")\n",
    "\n",
    "for img_path in image_files:\n",
    "    # Get base filename (without path and extension)\n",
    "    base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    \n",
    "    # Try to find corresponding mask with either extension\n",
    "    mask_path = None\n",
    "    for mask_ext in ['_masks.tif', '_masks.tiff']:\n",
    "        candidate_path = f\"./data/instance_masks/{base_name}{mask_ext}\"\n",
    "        if os.path.exists(candidate_path):\n",
    "            mask_path = candidate_path\n",
    "            break\n",
    "    \n",
    "    # Check if mask exists\n",
    "    if mask_path is None:\n",
    "        print(f\"Warning: Mask not found for {base_name}, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Processing: {base_name}\")\n",
    "    \n",
    "    # Load original image\n",
    "    img = Image.open(img_path)\n",
    "    img_np = np.array(img)\n",
    "\n",
    "    # Load mask\n",
    "    mask = Image.open(mask_path)\n",
    "    mask_np = np.array(mask)\n",
    "\n",
    "    # If mask is RGB, take one channel\n",
    "    if mask_np.ndim == 3:\n",
    "        mask_np = mask_np[..., 0]\n",
    "\n",
    "    # Normalize image for display - improved version with subtle contrast enhancement\n",
    "    if img.mode not in ['RGB', 'L', 'RGBA']:\n",
    "        if img.mode in ['I', 'I;16', 'F']:\n",
    "            # Normalize 16-bit or float images to 8-bit with subtle contrast stretching\n",
    "            img_array = img_np.copy().astype(np.float32)\n",
    "            \n",
    "            # Use gentler percentile-based contrast stretching\n",
    "            p_low = np.percentile(img_array, 0.5)\n",
    "            p_high = np.percentile(img_array, 99.5)\n",
    "            \n",
    "            # Clip and normalize\n",
    "            img_array = np.clip(img_array, p_low, p_high)\n",
    "            img_array = ((img_array - p_low) / (p_high - p_low) * 255).astype(np.uint8)\n",
    "            \n",
    "            img = Image.fromarray(img_array, mode='L')\n",
    "            img_disp = img_array\n",
    "        else:\n",
    "            img = img.convert('L')\n",
    "            img_disp = np.array(img)\n",
    "    else:\n",
    "        # Apply subtle contrast stretching to 8-bit images too\n",
    "        img_array = img_np.copy().astype(np.float32)\n",
    "        p_low = np.percentile(img_array, 0.5)\n",
    "        p_high = np.percentile(img_array, 99.5)\n",
    "        img_array = np.clip(img_array, p_low, p_high)\n",
    "        img_disp = ((img_array - p_low) / (p_high - p_low) * 255).astype(np.uint8)\n",
    "\n",
    "    print(f\"  Image shape: {img_np.shape}, dtype: {img_np.dtype}, mode: {img.mode}\")\n",
    "    print(f\"  Mask shape: {mask_np.shape}, unique values: {len(np.unique(mask_np))}\")\n",
    "\n",
    "    # -----------------------\n",
    "    # Pre-compute colors for ALL objects (fixed seed for consistency)\n",
    "    # -----------------------\n",
    "    rng = np.random.default_rng(42)  # Fixed seed\n",
    "    all_instance_ids = np.unique(mask_np)\n",
    "    color_map = {}\n",
    "    for instance_id in all_instance_ids:\n",
    "        if instance_id == 0:  # Skip background\n",
    "            continue\n",
    "        color_map[instance_id] = rng.random(3)\n",
    "\n",
    "    print(f\"  Created color map for {len(color_map)} unique objects\")\n",
    "\n",
    "    # -----------------------\n",
    "    # Create full image overlay\n",
    "    # -----------------------\n",
    "    rgb_mask_full = np.zeros((*mask_np.shape, 3), dtype=np.float32)\n",
    "    for instance_id in np.unique(mask_np):\n",
    "        if instance_id == 0:\n",
    "            continue\n",
    "        rgb_mask_full[mask_np == instance_id] = color_map[instance_id]\n",
    "\n",
    "    # Create full overlay\n",
    "    overlay_full = np.stack([img_disp, img_disp, img_disp], axis=-1).astype(np.float32) / 255.0\n",
    "    overlay_full = overlay_full * 0.6 + rgb_mask_full * 0.4\n",
    "    overlay_full = (overlay_full * 255).astype(np.uint8)\n",
    "\n",
    "    # Save full overlay with same filename\n",
    "    output_path = f\"./data/overlay/{base_name}_overlay.tif\"\n",
    "    Image.fromarray(overlay_full).save(output_path)\n",
    "    print(f\"  Saved overlay to {output_path}\\n\")\n",
    "\n",
    "print(\"All files processed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c07fa42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 image files to process\n",
      "\n",
      "Processing: 20211222_125057_petiole4_00012\n",
      "  Image shape: (2560, 2560), dtype: float32, mode: L\n",
      "  Mask shape: (2560, 2560), unique values: 2085\n",
      "  Created color map for 2084 unique objects\n",
      "  Saved RGB overlay to ./data/overlay/20211222_125057_petiole4_00012_overlay.tif\n",
      "  Saved grayscale TIFF with shape (1, 2560, 2560): ./data/overlay/20211222_125057_petiole4_00012_overlay_gray.tif\n",
      "\n",
      "All files processed!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import tifffile as tiff\n",
    "\n",
    "def rgb_tif_to_gray_tif(\n",
    "    input_tif: str,\n",
    "    output_tif: str,\n",
    "    method: str = \"luminance\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert a 3-channel TIFF to a grayscale TIFF with shape [1, H, W].\n",
    "    \"\"\"\n",
    "    img = tiff.imread(input_tif)\n",
    "\n",
    "    if img.ndim != 3 or img.shape[-1] != 3:\n",
    "        raise ValueError(f\"Expected 3-channel TIFF, got shape {img.shape}\")\n",
    "\n",
    "    in_dtype = img.dtype\n",
    "    img = img.astype(np.float32)\n",
    "\n",
    "    if method == \"luminance\":\n",
    "        gray = (\n",
    "            0.299 * img[..., 0] +\n",
    "            0.587 * img[..., 1] +\n",
    "            0.114 * img[..., 2]\n",
    "        )\n",
    "    elif method == \"average\":\n",
    "        gray = img.mean(axis=-1)\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'luminance' or 'average'\")\n",
    "\n",
    "    # Restore dtype\n",
    "    if np.issubdtype(in_dtype, np.integer):\n",
    "        max_val = np.iinfo(in_dtype).max\n",
    "        gray = np.clip(gray, 0, max_val).astype(in_dtype)\n",
    "\n",
    "    # ðŸ”´ ADD CHANNEL AXIS â†’ (1, H, W)\n",
    "    gray = gray[np.newaxis, :, :]\n",
    "\n",
    "    # Save without squeezing\n",
    "    tiff.imwrite(\n",
    "        output_tif,\n",
    "        gray,\n",
    "        photometric=\"minisblack\"\n",
    "    )\n",
    "\n",
    "    print(f\"  Saved grayscale TIFF with shape {gray.shape}: {output_tif}\")\n",
    "\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(\"./data/overlay\", exist_ok=True)\n",
    "\n",
    "# Get all .tiff and .tif files from images directory\n",
    "image_files = glob.glob(\"./data/images/*.tiff\") + glob.glob(\"./data/images/*.tif\")\n",
    "\n",
    "print(f\"Found {len(image_files)} image files to process\\n\")\n",
    "\n",
    "for img_path in image_files:\n",
    "    # Get base filename (without path and extension)\n",
    "    base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    \n",
    "    # Try to find corresponding mask with either extension\n",
    "    mask_path = None\n",
    "    for mask_ext in ['_masks.tif', '_masks.tiff']:\n",
    "        candidate_path = f\"./data/instance_masks/{base_name}{mask_ext}\"\n",
    "        if os.path.exists(candidate_path):\n",
    "            mask_path = candidate_path\n",
    "            break\n",
    "    \n",
    "    # Check if mask exists\n",
    "    if mask_path is None:\n",
    "        print(f\"Warning: Mask not found for {base_name}, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Processing: {base_name}\")\n",
    "    \n",
    "    # Define output paths\n",
    "    output_path = f\"./data/overlay/{base_name}_overlay.tif\"\n",
    "    gray_output_path = f\"./data/overlay/{base_name}_overlay_gray.tif\"\n",
    "    \n",
    "    # Check if gray overlay already exists\n",
    "    gray_exists = os.path.exists(gray_output_path)\n",
    "    \n",
    "    # Skip if gray overlay exists (no need to create RGB overlay either)\n",
    "    if gray_exists:\n",
    "        print(f\"  Gray overlay already exists, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    # Load original image\n",
    "    img = Image.open(img_path)\n",
    "    img_np = np.array(img)\n",
    "\n",
    "    # Load mask\n",
    "    mask = Image.open(mask_path)\n",
    "    mask_np = np.array(mask)\n",
    "\n",
    "    # If mask is RGB, take one channel\n",
    "    if mask_np.ndim == 3:\n",
    "        mask_np = mask_np[..., 0]\n",
    "\n",
    "    # Normalize image for display - improved version with subtle contrast enhancement\n",
    "    if img.mode not in ['RGB', 'L', 'RGBA']:\n",
    "        if img.mode in ['I', 'I;16', 'F']:\n",
    "            # Normalize 16-bit or float images to 8-bit with subtle contrast stretching\n",
    "            img_array = img_np.copy().astype(np.float32)\n",
    "            \n",
    "            # Use gentler percentile-based contrast stretching\n",
    "            p_low = np.percentile(img_array, 0.5)\n",
    "            p_high = np.percentile(img_array, 99.5)\n",
    "            \n",
    "            # Clip and normalize\n",
    "            img_array = np.clip(img_array, p_low, p_high)\n",
    "            img_array = ((img_array - p_low) / (p_high - p_low) * 255).astype(np.uint8)\n",
    "            \n",
    "            img = Image.fromarray(img_array, mode='L')\n",
    "            img_disp = img_array\n",
    "        else:\n",
    "            img = img.convert('L')\n",
    "            img_disp = np.array(img)\n",
    "    else:\n",
    "        # Apply subtle contrast stretching to 8-bit images too\n",
    "        img_array = img_np.copy().astype(np.float32)\n",
    "        p_low = np.percentile(img_array, 0.5)\n",
    "        p_high = np.percentile(img_array, 99.5)\n",
    "        img_array = np.clip(img_array, p_low, p_high)\n",
    "        img_disp = ((img_array - p_low) / (p_high - p_low) * 255).astype(np.uint8)\n",
    "\n",
    "    print(f\"  Image shape: {img_np.shape}, dtype: {img_np.dtype}, mode: {img.mode}\")\n",
    "    print(f\"  Mask shape: {mask_np.shape}, unique values: {len(np.unique(mask_np))}\")\n",
    "\n",
    "    # -----------------------\n",
    "    # Pre-compute colors for ALL objects (fixed seed for consistency)\n",
    "    # -----------------------\n",
    "    rng = np.random.default_rng(42)  # Fixed seed\n",
    "    all_instance_ids = np.unique(mask_np)\n",
    "    color_map = {}\n",
    "    for instance_id in all_instance_ids:\n",
    "        if instance_id == 0:  # Skip background\n",
    "            continue\n",
    "        color_map[instance_id] = rng.random(3)\n",
    "\n",
    "    print(f\"  Created color map for {len(color_map)} unique objects\")\n",
    "\n",
    "    # -----------------------\n",
    "    # Create full image overlay\n",
    "    # -----------------------\n",
    "    rgb_mask_full = np.zeros((*mask_np.shape, 3), dtype=np.float32)\n",
    "    for instance_id in np.unique(mask_np):\n",
    "        if instance_id == 0:\n",
    "            continue\n",
    "        rgb_mask_full[mask_np == instance_id] = color_map[instance_id]\n",
    "\n",
    "    # Create full overlay\n",
    "    overlay_full = np.stack([img_disp, img_disp, img_disp], axis=-1).astype(np.float32) / 255.0\n",
    "    overlay_full = overlay_full * 0.6 + rgb_mask_full * 0.4\n",
    "    overlay_full = (overlay_full * 255).astype(np.uint8)\n",
    "\n",
    "    # Save full RGB overlay\n",
    "    Image.fromarray(overlay_full).save(output_path)\n",
    "    print(f\"  Saved RGB overlay to {output_path}\")\n",
    "    \n",
    "    # Convert RGB overlay to grayscale\n",
    "    rgb_tif_to_gray_tif(\n",
    "        output_path,\n",
    "        gray_output_path,\n",
    "        method=\"luminance\"\n",
    "    )\n",
    "    print()\n",
    "\n",
    "print(\"All files processed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331544f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def find_class_contours(semantic_mask, class_id):\n",
    "    \"\"\"\n",
    "    Find contours for a specific class in the semantic mask.\n",
    "    \n",
    "    Args:\n",
    "        semantic_mask: semantic segmentation mask\n",
    "        class_id: the class ID to find contours for\n",
    "    \n",
    "    Returns:\n",
    "        list of contours\n",
    "    \"\"\"\n",
    "    # Create binary mask for this class\n",
    "    binary_mask = (semantic_mask == class_id).astype(np.uint8)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    return contours\n",
    "\n",
    "\n",
    "def draw_polygons_on_image(img_normalized, semantic_mask, class_colors):\n",
    "    \"\"\"\n",
    "    Draw polygon boundaries for each class on the normalized image.\n",
    "    \n",
    "    Args:\n",
    "        img_normalized: normalized grayscale image\n",
    "        semantic_mask: semantic segmentation mask\n",
    "        class_colors: dictionary mapping class IDs to RGB colors\n",
    "    \n",
    "    Returns:\n",
    "        image with polygons drawn\n",
    "    \"\"\"\n",
    "    # Convert to RGB if grayscale\n",
    "    if len(img_normalized.shape) == 2:\n",
    "        img_with_polygons = np.stack([img_normalized] * 3, axis=-1)\n",
    "    else:\n",
    "        img_with_polygons = img_normalized.copy()\n",
    "    \n",
    "    # Get unique classes (excluding background class 0)\n",
    "    unique_classes = np.unique(semantic_mask)\n",
    "    unique_classes = unique_classes[unique_classes != 0]\n",
    "    \n",
    "    # Draw contours for each class\n",
    "    for class_id in unique_classes:\n",
    "        contours = find_class_contours(semantic_mask, class_id)\n",
    "        color = class_colors.get(int(class_id), [255, 255, 255])\n",
    "        \n",
    "        # Draw contours with thick lines\n",
    "        cv2.drawContours(img_with_polygons, contours, -1, color, thickness=3)\n",
    "    \n",
    "    return img_with_polygons\n",
    "\n",
    "\n",
    "def visualize_and_save(original_img, semantic_mask, output_path, norm_images_dir):\n",
    "    \"\"\"\n",
    "    Visualize semantic mask as overlay on original image and save both.\n",
    "    \n",
    "    Args:\n",
    "        original_img: original image array\n",
    "        semantic_mask: semantic segmentation mask\n",
    "        output_path: path to save the semantic mask\n",
    "        norm_images_dir: directory to save normalized images\n",
    "    \"\"\"\n",
    "    # Define colors for each class\n",
    "    class_colors = {\n",
    "        0: [128, 128, 128],  # Gray - Background\n",
    "        1: [0, 0, 255],      # Blue - Cortex\n",
    "        2: [0, 255, 0],      # Green - Phloem Fibers\n",
    "        3: [128, 0, 128],    # Purple - Phloem\n",
    "        4: [255, 0, 0],      # Red - Xylem vessels\n",
    "        5: [255, 255, 0],    # Yellow - Air-based Pith cells\n",
    "        6: [255, 165, 0],    # Orange - Water-based Pith cells\n",
    "    }\n",
    "    \n",
    "    # Create colored semantic mask\n",
    "    h, w = semantic_mask.shape\n",
    "    colored_mask = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    \n",
    "    for class_id, color in class_colors.items():\n",
    "        colored_mask[semantic_mask == class_id] = color\n",
    "    \n",
    "    # Print class distribution\n",
    "    unique_classes = np.unique(semantic_mask)\n",
    "    print(f\"Classes present: {unique_classes}\")\n",
    "    for class_id in unique_classes:\n",
    "        pixel_count = np.sum(semantic_mask == class_id)\n",
    "        print(f\"Class {class_id}: {pixel_count} pixels\")\n",
    "    \n",
    "    # Normalize original image\n",
    "    img_array = original_img.copy().astype(np.float32)\n",
    "    \n",
    "    # Use percentile-based contrast stretching\n",
    "    p_low = np.percentile(img_array, 0.5)\n",
    "    p_high = np.percentile(img_array, 99.5)\n",
    "    \n",
    "    # Clip and normalize\n",
    "    img_array = np.clip(img_array, p_low, p_high)\n",
    "    img_normalized = ((img_array - p_low) / (p_high - p_low) * 255).astype(np.uint8)\n",
    "    \n",
    "    # Save normalized image\n",
    "    norm_image_path = norm_images_dir / f\"{output_path.stem.replace('_semantic_mask', '')}_normalized.png\"\n",
    "    Image.fromarray(img_normalized).save(norm_image_path)\n",
    "    print(f\"Normalized image saved to: {norm_image_path}\")\n",
    "    \n",
    "    # Convert to RGB if grayscale\n",
    "    if len(img_normalized.shape) == 2:\n",
    "        img_normalized_rgb = np.stack([img_normalized] * 3, axis=-1)\n",
    "    else:\n",
    "        img_normalized_rgb = img_normalized\n",
    "    \n",
    "    # Create overlay with transparency\n",
    "    alpha = 0.2\n",
    "    overlay = cv2.addWeighted(img_normalized_rgb, 1-alpha, colored_mask, alpha, 0)\n",
    "    \n",
    "    # Draw polygons on normalized image\n",
    "    img_with_polygons = draw_polygons_on_image(img_normalized, semantic_mask, class_colors)\n",
    "    \n",
    "    # Save colored semantic mask (same colors as overlay)\n",
    "    Image.fromarray(colored_mask).save(output_path)\n",
    "    print(f\"Colored semantic mask saved to: {output_path}\")\n",
    "    \n",
    "    # Save overlay image in the same directory\n",
    "    overlay_path = output_path.parent / f\"{output_path.stem}_overlay.png\"\n",
    "    Image.fromarray(overlay).save(overlay_path)\n",
    "    print(f\"Overlay image saved to: {overlay_path}\")\n",
    "    \n",
    "    # Save image with polygons\n",
    "    polygon_path = output_path.parent / f\"{output_path.stem}_polygons.png\"\n",
    "    Image.fromarray(img_with_polygons).save(polygon_path)\n",
    "    print(f\"Image with polygons saved to: {polygon_path}\")\n",
    "    \n",
    "    # Visualize (now with 4 subplots)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(18, 18))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    axes[0].imshow(img_normalized, cmap='gray')\n",
    "    axes[0].set_title('Original Image (Normalized)', fontsize=12, fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(colored_mask)\n",
    "    axes[1].set_title('Semantic Mask', fontsize=12, fontweight='bold')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    axes[2].imshow(overlay)\n",
    "    axes[2].set_title('Overlay (20% transparency)', fontsize=12, fontweight='bold')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    axes[3].imshow(img_with_polygons)\n",
    "    axes[3].set_title('Polygon Boundaries', fontsize=12, fontweight='bold')\n",
    "    axes[3].axis('off')\n",
    "    \n",
    "    # Add legend\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [\n",
    "        Patch(facecolor=np.array(class_colors[i])/255, label=f'Class {i}')\n",
    "        for i in sorted(class_colors.keys())\n",
    "    ]\n",
    "    axes[3].legend(handles=legend_elements, loc='upper right', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def process_single_file(image_path, mask_path, output_path, norm_images_dir):\n",
    "    \"\"\"\n",
    "    Process a single image and mask file to create overlay visualization.\n",
    "    \n",
    "    Args:\n",
    "        image_path: path to the original image\n",
    "        mask_path: path to the .npy mask file\n",
    "        output_path: path to save the semantic mask\n",
    "        norm_images_dir: directory to save normalized images\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Processing: {Path(image_path).name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Load image\n",
    "    original_img = np.array(Image.open(image_path))\n",
    "    print(f\"Image shape: {original_img.shape}\")\n",
    "    \n",
    "    # Load mask\n",
    "    semantic_mask = np.load(mask_path)\n",
    "    print(f\"Mask shape: {semantic_mask.shape}\")\n",
    "    \n",
    "    # Visualize and save\n",
    "    print(\"\\nVisualizing and saving...\")\n",
    "    visualize_and_save(original_img, semantic_mask, output_path, norm_images_dir)\n",
    "\n",
    "\n",
    "def batch_process(images_dir, masks_dir, output_dir, norm_images_dir):\n",
    "    \"\"\"\n",
    "    Process all matching files in the specified directories.\n",
    "    \n",
    "    Args:\n",
    "        images_dir: directory containing image files (.tiff or .tif)\n",
    "        masks_dir: directory containing mask files (*_mask.npy)\n",
    "        output_dir: directory to save semantic masks and overlays\n",
    "        norm_images_dir: directory to save normalized images\n",
    "    \"\"\"\n",
    "    # Create output directories if they don't exist\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    norm_images_dir = Path(norm_images_dir)\n",
    "    norm_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Get all image files\n",
    "    images_dir = Path(images_dir)\n",
    "    image_files = list(images_dir.glob(\"*.tiff\")) + list(images_dir.glob(\"*.tif\"))\n",
    "    \n",
    "    print(f\"Found {len(image_files)} image files\")\n",
    "    \n",
    "    processed_count = 0\n",
    "    skipped_count = 0\n",
    "    \n",
    "    for image_path in sorted(image_files):\n",
    "        base_name = image_path.stem\n",
    "        \n",
    "        # Find corresponding mask file\n",
    "        masks_dir_path = Path(masks_dir)\n",
    "        mask_path = masks_dir_path / f\"{base_name}_mask.npy\"\n",
    "        \n",
    "        # Check if mask file exists\n",
    "        if not mask_path.exists():\n",
    "            print(f\"\\nSkipping {base_name}: mask file not found\")\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "        \n",
    "        # Output path for semantic mask (will also save overlay in same directory)\n",
    "        output_path = output_dir / f\"{base_name}_semantic_mask.png\"\n",
    "        \n",
    "        # Process the files\n",
    "        try:\n",
    "            process_single_file(image_path, mask_path, output_path, norm_images_dir)\n",
    "            processed_count += 1\n",
    "            # Close all matplotlib figures to free memory\n",
    "            plt.close('all')\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing {base_name}: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            skipped_count += 1\n",
    "            # Close all matplotlib figures even on error\n",
    "            plt.close('all')\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Batch processing complete!\")\n",
    "    print(f\"Processed: {processed_count} files\")\n",
    "    print(f\"Skipped: {skipped_count} files\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Batch process all files\n",
    "    images_dir = \"./data/images\"\n",
    "    masks_dir = \"./data/annotations\"  # Directory containing *_mask.npy files\n",
    "    output_dir = \"./data/semantic_masks\"\n",
    "    norm_images_dir = \"./data/norm_images\"\n",
    "    \n",
    "    batch_process(images_dir, masks_dir, output_dir, norm_images_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
